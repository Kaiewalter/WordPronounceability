{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRONOUNCEABILITY PROBABILITY: HAVE MAX GRADE\n",
    "### By: Ethan Ringel, Jayden Andrews, Kai Walter\n",
    "\n",
    "Our group shares a burning interest in the English language, more specifically, how words are created and spoken. Our thoughts led us to want to perform Data Science on word pronounceability, more specifically on how to determine whether a word is pronounceable or not. We attempted to develop a heuristic which, when given a completely random string of letters, could determine whether that word is pronounceable by English speaking people. \n",
    "\n",
    "Additionally, after developing this heuristic, we decided to test its effectiveness by comparing the accuracy of our heuristic to the accuracy of various machine learning algorithms which we would run on datasets of pronounceable and unpronounceable words.\n",
    "\n",
    "# Task 1: Data Collection/Curation + Parsing\n",
    "\n",
    "In order to run ML algorithms to determine whether a word is pronounceable or not as well as run our self made heuristic, we needed a dataset containing words which we could identify as either pronounceable or not pronounceable*.\n",
    "\n",
    "*One thing to note about the pronounceability of a word is that there exists some nuance to this issue. Technically speaking, an English speaker may attempt to pronounce any given sequence of letters and deem a particular pronunciation correct, which would then make that word “pronounceable.” However, our classification of pronounceability focuses more on how easy it would be for an English speaker to view a word and determine the correct pronunciation. For example, if we took two gibberish words “matcutious” and “xzvuopowmf,” we see that one of these words seems far more sensicle given prior knowledge of English conventions. Thus we would likely deem “matcutious” pronounceable and “xzvuopowmf” unpronounceable.\n",
    "\n",
    "### Idea #1:\n",
    "We imported a large (literal) dictionary containing upwards of 300,000 English words; however, we ran into two primary issues with this approach:\n",
    "Regardless of which dataset we imported, the dataset would contain many nonsensical words as well as words which contained many difficult characters to handle such as spaces, hyphens, apostrophes, etc. and there was little we could do to remove these words or work around them\n",
    "With over 300,000 data points, attempting to represent our data through one-hot encoded bigrams was impossible and simply wouldn’t run on any of our systems\n",
    "\n",
    "### Idea #2:\n",
    "Through some brainstorming, we concluded that we could instead import a dataset which contained the most common words in the English language sorted by their general frequency and truncate this dataset at a certain quantity. Our reasoning behind this decision was that we would simultaneously be able to reduce the size of our dataset while filtering out many of the nonsensical words (because they would likely have very low frequency values). Additionally, we reasoned that English words that appear most often in everyday use would be far easier to pronounce for the given English speaker, so a set of the most common words would be more valuable than a set simply containing every word ever created.\n",
    "\n",
    "\n",
    "### Finalized Approach\n",
    "With that in mind, we went with idea #2, importing a dataset of the most commonly used English words and isolating the 3000 most common English words, solving our issue of obtaining data for pronounceable words.\n",
    "\n",
    "Obtaining data for unpronounceable words was an entirely different process. There simply do not exist datasets filled with gibberish that can’t be pronounced, so we decided to write our own method to generate these unpronounceable words. \n",
    "\n",
    "In order to generate unpronounceable words, we used three general rules which we viewed as making a word difficult to pronounce.\n",
    "The word has a long substring of adjacent consonants\n",
    "The frequency of vowels is relatively low\n",
    "The word contains the letter q without being followed by u or being at the end of the word\n",
    "\n",
    "From here we used these rules to generate random strings, determine if they fit any of the unpronounceable criteria, and if so, add them to our collection of unpronounceable words. This then solved our issue of attaining a list of unpronounceable words**.\n",
    "\n",
    "**There are obviously countless more rules regarding how letters interact in English which relate to pronounceability or lack thereof which we can’t account for in our generation of unpronounceable words. However, our three rules seem to produce rather consistent results in the sense that most of the words generated are quite difficult to pronounce which we deemed sufficient for the sake of our model.\n",
    "\n",
    "## Task 2: Data management/representation\n",
    "At this point, we now had a full list of words, both pronounceable and unpronounceable, resulting from our collection of the most common English words and generation of unpronounceable words. From here we needed a way to turn this categorical data into numerical data which could be fed into our various ML algorithms.\n",
    "\n",
    "For this we decided to one-hot encode bigrams. The point of using bigrams as opposed to another possible means of dividing each word was that bigrams best mimic the syllables contained within each word, which are the base units of each word that determine its pronunciation.\n",
    "\n",
    "To one-hot encode the bigrams within each word in our collection, we would represent each word with a vector of length 676 (with each element of this vector representing a possible bigram, 262 = 676). Thus our feature vector would be formatted as [“aa”: int, “ab”: int, …, “zz”: int]. For example, if we took the word “abba” our resulting vector would be [“aa”: 0, “ab”: 1, …, “ba”: 1, “bb”: 1, … “zz”: 0].\n",
    "\n",
    "To isolate the bigram, we defined a helper method which would take a word as an argument and return a list of all the bigrams contained within that word. For example, if we passed in “hello”, the method would return [“he”, “el”, “ll”, “lo”].\n",
    "\n",
    "Combining this helper method with our intended representation of the data, we could now take our collection of words, isolate the bigrams of each word, and then put our data into one large dataframe, where each word would be represented by a vector of length 676."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Methods\n",
    "update_progress: Implements progess bar (added because of time-intensity of certain algorithms)\n",
    "\n",
    "get_bigrams: As described above, returns bigrams contained within a word\n",
    "\n",
    "foldl: Small implementation of fold left \n",
    "\n",
    "is_probability: Returns whether or not a variable is a valid probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def update_progress(progress, label: str = \"\"):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress, 0))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = label+\"\\nProgress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)\n",
    "\n",
    "\n",
    "def get_bigrams(word:str) -> list:\n",
    "    return [i+j for i, j in \\\n",
    "            zip(word, word[1:])]\n",
    "\n",
    "\n",
    "import functools\n",
    "def foldl(func, xs, acc):\n",
    "    return functools.reduce(func, xs, acc)\n",
    "\n",
    "def is_probability(input):\n",
    "    return isinstance(input, float) and \\\n",
    "        input >= 0 and \\\n",
    "            input <= 1\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Variables\n",
    "letter_likelihood: Holds the likelihood value for possible bigrams based on how often they appear within a dictionary\n",
    "\n",
    "accuracy_dict: Will contain the accuracy values for each algorithm (heuristic + 5 ML algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_likelihood = {}\n",
    "accuracy_dict = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization Code\n",
    "As described in prose in task 2, these helper methods will help represent a word as a 676-dimensional feature vector where all bigrams are one-hot encoded.\n",
    "\n",
    "generate_feature_vector: Will generate the feature vector for either a single string or a list of strings\n",
    "\n",
    "get_vectors_for_series: Generates above feature vectors for a pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "import string\n",
    "\n",
    "def generate_feature_vector(input):\n",
    "    # we will be outsourcing this to a c subprocess to increase perf\n",
    "    if(\"str\" in str(type(input))):\n",
    "        return generate_feature_vector(get_bigrams(input))\n",
    "    elif(\"list\" in str(type(input))):\n",
    "        feature_vector = {\n",
    "            str(bigram) : 1 if (str(bigram[0])+str(bigram[1])) in input else 0 \\\n",
    "                for bigram in \\\n",
    "                    [i+j for i in string.ascii_lowercase for j in string.ascii_lowercase]\n",
    "        }\n",
    "        return feature_vector\n",
    "    else:\n",
    "        print(input)\n",
    "        raise TypeError(f\"Requires either 'str' or List[str] as input for generate_feature_vector(), found {type(input)}.\")\n",
    "        \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def get_vectors_for_series(data: pd.Series, label: str):\n",
    "    vectors = []\n",
    "    length = len(data)\n",
    "    for i in range(length):\n",
    "        word = data.loc[i]\n",
    "        if i % 5 == 0 or i == length:\n",
    "            update_progress(i / length, label=label)\n",
    "        vectors.append(np.asarray(list(generate_feature_vector(get_bigrams(word)).values())))\n",
    "    return pd.Series(vectors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Creation Code\n",
    "These helper methods are used to generate lists of pronounceable and unpronounceable words based on the aforementioned rules regarding generation.\n",
    "\n",
    "get_n_pronounceable_words: Returns a set of n pronounceable words\n",
    "\n",
    "get_n_unpronounceable_words: Returns a set of n unpronounceable words\n",
    "\n",
    "get_dataset: Returns of set of n unpronouceable words and n pronounceable words along with classification labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import typing\n",
    "import math\n",
    "\n",
    "def get_n_pronounceable_words(n: int) -> typing.Set[str]:\n",
    "    data_path = os.path.normpath(os.path.join(os.path.dirname(os.path.abspath(\"word_pronounceability.ipynb\")), '..', 'unigram_freq.csv'))\n",
    "    dataframe = pd.read_csv(data_path)\n",
    "    dataframe = dataframe[dataframe.word.str.len() >= 3]\n",
    "    dataframe = dataframe.set_axis(range(0, dataframe.shape[0]), axis=0)\n",
    "    \n",
    "    sample_size_n = dataframe.sample(n = n)\n",
    "    return set(sample_size_n[\"word\"])\n",
    "\n",
    "def get_n_unpronounceable_words(n: int) -> typing.Set[str]:\n",
    "    def norm(vector:list):\n",
    "        return math.sqrt(sum([i*i for i in vector]))\n",
    "        \n",
    "    words: typing.Set[str] = set()\n",
    "    while len(words) < n:\n",
    "        possible_word = ''.join(random.choice(string.ascii_lowercase) for _ in range(random.choice(list(range(3,15)))))\n",
    "\n",
    "        violates_q_u_rule = \"q\" in possible_word and \"qu\" not in possible_word\n",
    "\n",
    "        num_consecutive_consonants = foldl(lambda x, y: x+1 if y not in list(\"aeiouy\") else 0, possible_word, 0)\n",
    "        \n",
    "        contains_no_vowels = num_consecutive_consonants == len(possible_word)\n",
    "\n",
    "        incorrectness_vector = [0.8*(1 if contains_no_vowels else 0), 0.4*(num_consecutive_consonants/4)]\n",
    "        incorrectness_vector.append(0.8*(norm(incorrectness_vector)) if violates_q_u_rule else norm(incorrectness_vector))\n",
    "        # ADJUST IF THE WORDS ARE TOO PRONOUNCEABLE\n",
    "        if norm(incorrectness_vector) > 0.7 and possible_word not in words:\n",
    "            words.add(possible_word)\n",
    "    return words\n",
    "\n",
    "\n",
    "def get_dataset(size: int) -> pd.DataFrame:\n",
    "    \"\"\"Generates a dataset of \"words.\" Half are pronounceable, half are not\n",
    "\n",
    "    Args:\n",
    "        size (int): Size of each half of the dataset (pronounceable / unpronounceable)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe with two columns: \"word\" and \"is_pronounceable\" with `2*size` rows.\n",
    "    \"\"\"\n",
    "    data_set = pd.DataFrame(list(get_n_pronounceable_words(size)) + (list((get_n_unpronounceable_words(size)))), columns=[\"word\"])\n",
    "    data_set[\"is_pronounceable\"] = data_set.index < size\n",
    "    return data_set\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic Model\n",
    "Our initial hypothesis was that the pronounceability of a word correlated very strongly with it's *likelihood*. This is to say, if it is statistically probable that a sequence of letters could make a word, it is also statistically probable that it can be pronounced. This is not without caveats, however: especially because we have idiomatically accepted brand names like \"Exxon\" which contain strings of letters which no (or at least very few) dictionary words contain. This fact would drive down the likelihood that these such strings of letters would appear, yet we can pronounce them perfectly fine. However, despite these caveats, we feel that this is a reasonable heuristic.\n",
    "\n",
    "## Heuristic Model Code\n",
    "pronounceable_score_heuristic: Given a bigram, function will check the number of times this bigram appear within a collection of pronounceable words. Based on the value for each bigram, will then condense these values into a final score for the bigram.\n",
    "\n",
    "is_pronounceable_heuristic: Given a word, function will disect it into its bigrams; for each bigram within the word it calls the pronouceable_score_heuristic function; finds the average of these scores and returns true (pronounceable) if the value is above a particular threshold and returns false (unpronouceable) if the value if below the threshold.\n",
    "\n",
    "For the latter, we set the value of the threshold to 0.1 after some tuning. We found that a threshold close to 0 would yield around 50% accuracy and that thesholds above 0.5 resulted in similar accuracies. However, at a value of 0.1, the accuracy was able to spike around 85-90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from statistics import mean\n",
    "def pronounceable_score_heuristic(letters: str) -> float:\n",
    "    \"\"\" Generates a numerical score representing the likelihood that a word is pronounceable.\n",
    "\n",
    "    Args:\n",
    "        letters (str): string of length 2 (bigram) containing only alphabetical characters to check our dataset for occurrences of\n",
    "\n",
    "    Returns:\n",
    "        float: a score representing the likelihood that we can pronounce this string of letters. 0.5 is generally pronounceable, 0.2 is not.\n",
    "    \"\"\"\n",
    "    assert len(letters) == 2\n",
    "    # if we have already checked this bigram, it'll be in our letter_likelihood dictionary, we can return it\n",
    "    if letters in letter_likelihood:\n",
    "        return letter_likelihood[letters]\n",
    "\n",
    "    # otherwise,\n",
    "    # check dataset for occurrences of [letters].\n",
    "    data = list(get_n_pronounceable_words(9000))\n",
    "    proportion = dict(in_line=0, not_in=0)\n",
    "    for word in data:\n",
    "        proportion['in_line' if letters in word else \"not_in\"] += 1\n",
    "    proportion['in_line'] -= 1 if (not proportion['in_line'] > 0) else 0\n",
    "    # if the set of letters is never found, then it almost certainly can't be pronounced, or possibly is simply not in our dataset.\n",
    "    # return the amount of times it was found divided by the total lines in the file (multiply by 10 to trim leading zeroes)\n",
    "    letter_likelihood[letters] = (proportion['in_line'] / sum([proportion[key] for key in proportion]))*10 \n",
    "    return letter_likelihood[letters]\n",
    "def is_pronounceable_heuristic(word: str) -> bool:\n",
    "    # Threshold of 0 gives 50% accuracy, anything above  0.5 gives 50% accuracy\n",
    "    THRESHOLD = 0.1\n",
    "\n",
    "    # turns word into list of bigrams into their likelihood of showing up in our dataset\n",
    "    # \"hello\" ->  [\"he\", \"el\", \"ll\", \"lo\"] -> [0.45..., 0.62..., 0.57..., 0.44...]\n",
    "    average_score = mean([pronounceable_score_heuristic(bigram) for bigram in get_bigrams(word)])\n",
    "\n",
    "    # if the average pronounceability score is too low, we assume it isn't pronounceable.\n",
    "    return average_score >= THRESHOLD\n",
    "\n",
    "\n",
    "# this function allows for more concise and readable code in our test flow.\n",
    "# uses a contextlib contextmanager to implement __enter__ and __exit__ for our function so we can use it in 'with' statements.\n",
    "@contextmanager\n",
    "def heuristic_function():\n",
    "    function = is_pronounceable_heuristic\n",
    "    try:\n",
    "        yield function\n",
    "    finally:\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined our heuristic model, we can test it on a large segment of data and check to see if it appropriately classifies incoming data. Additionally, now that we have defined our helper methods to organize the necessary data for running our ML algorithms, we can run those and compare the scores to that of our heuristic.\n",
    "\n",
    "# Task 3: Exploratory data analysis\n",
    "In order to properly display our data, we decided to use five machine learning algorithms. We decided to use Naive Bayes’ algorithm, a k-Nearest neighbor algorithm, semi-supervised model label propagation, a support vector machine, and a neural network. We recognize that not all of these algorithms were necessarily comparable to each other, but we thought that it was important to compare the differences between all of them to properly display our findings. The results were as follows.\n",
    "\n",
    "### Heuristic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_heuristic = False\n",
    "with heuristic_function() as is_pronounceable:\n",
    "    if not skip_heuristic:\n",
    "        test_data = pd.DataFrame(columns=[\"word\", \"is_pronounceable\"])\n",
    "        pronounceable_data = pd.DataFrame(columns=[\"word\"], data=pd.Series(list(get_n_pronounceable_words(1000))))\n",
    "        pronounceable_data[\"is_pronounceable\"] = True\n",
    "\n",
    "        unpronounceable_data = pd.DataFrame(columns=[\"word\"], data=pd.Series(list(get_n_unpronounceable_words(1000))))\n",
    "        unpronounceable_data[\"is_pronounceable\"] = False\n",
    "\n",
    "        test_data = pd.concat(objs=[pronounceable_data, unpronounceable_data])\n",
    "        scoring = dict(right= 0, total = 0)\n",
    "        for idx, row in test_data.iterrows():\n",
    "            update_progress(scoring[\"total\"] / test_data.shape[0])\n",
    "            if(is_pronounceable(row[\"word\"]) == row[\"is_pronounceable\"]):\n",
    "                # print(\"guessed correctly that \" + row[\"word\"] + \" is \" + (\"not \" if not row[\"is_pronounceable\"] else \"\") + \"pronounceable\")\n",
    "                scoring[\"right\"] += 1\n",
    "            # else:\n",
    "            #     print(\"guessed incorrectly that \" + row[\"word\"] + \" is \" + (\"\" if not row[\"is_pronounceable\"] else \"not \") + \"pronounceable\")\n",
    "            scoring[\"total\"] += 1\n",
    "        \n",
    "        accuracy_dict[\"Heuristic Model\"] = (scoring[\"right\"] / scoring[\"total\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Test\n",
    "Now that we have the ability to turn words into vectors (through one-hot encoding bigrams), we can begin to train models on these vectors. Since we are looking for a one-vs-one classification, we can use, for example:\n",
    "1. Naive Bayes\n",
    "2. K Nearest Neighbors\n",
    "3. Semi-Supervised Learning\n",
    "4. Support Vector Machines\n",
    "5. Neural Network\n",
    "\n",
    "### Training / Testing Data\n",
    "Splits our dataset containing 3000 pronounceable and 3000 unpronouceable words into training and testing sets used to fit and evaluate our ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 99.9%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "size = 3000 # size of each half of the dataset\n",
    "data_set = get_dataset(size)\n",
    "\n",
    "X_vectors = list(get_vectors_for_series(data_set[\"word\"], label=\"\"))\n",
    "\n",
    "# Convert from list of np arrays to single 2darray\n",
    "X = np.array([x for x in X_vectors])\n",
    "y = np.array([np.array(1 if i else 0) for i in data_set[\"is_pronounceable\"]])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, list(y), test_size=0.25, random_state=7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "naive_bayes_model = BernoulliNB()\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "\n",
    "accuracy_dict[\"Naive Bayes\"] = naive_bayes_model.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbors = 10\n",
    "knn_model = KNeighborsClassifier(n_neighbors=n_neighbors).fit(X_train, y_train)\n",
    "accuracy_dict[f\"K-Nearest-Neighbors ({n_neighbors} neighbors)\"] = knn_model.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-supervised Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.semi_supervised import LabelPropagation\n",
    "\n",
    "# get a \"LOT\" of extra data, and label it as -1\n",
    "\n",
    "words_unlabeled = pd.Series(list(get_n_pronounceable_words(4500).union(get_n_unpronounceable_words(4500))))\n",
    "X_unlabeled = np.array([i for i in list(get_vectors_for_series(words_unlabeled))])\n",
    "y_unlabeled = np.array([-1 for _ in X_unlabeled])\n",
    "\n",
    "\n",
    "X_mixed = np.concatenate((X_train, X_unlabeled), axis=0)\n",
    "\n",
    "y_mixed = np.concatenate((y_train, y_unlabeled), axis=0)\n",
    "\n",
    "\n",
    "semi_supervised_model = LabelPropagation().fit(X_mixed, y_mixed)\n",
    "\n",
    "\n",
    "accuracy_dict[\"Semi Supervised (Label Propagation)\"] = (semi_supervised_model.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "\n",
    "#TODO Tune parameters\n",
    "svc_model = NuSVC().fit(X_train, y_train)\n",
    "accuracy_dict[\"Support Vector Machine (NuSVC)\"]= (svc_model.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#  TODO Tune parameters:\n",
    "nn_model = MLPClassifier(learning_rate = \"invscaling\").fit(X_train, y_train)\n",
    "accuracy_dict[\"Neural Network (Multi-Layer Perceptron)\"] = (nn_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for most recent run:\n",
      "Accuracy for Heuristic Model: 88.7%\n"
     ]
    }
   ],
   "source": [
    "print(\"Stats for most recent run:\")\n",
    "for model in accuracy_dict:\n",
    "    print(f\"Accuracy for {model}: {str(accuracy_dict[model]*100)[:5]}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracies of our models were as such:\n",
    "\n",
    "Naive Bayes': 96.26%\n",
    "KNN: 91.2%\n",
    "Semi-Supervised: 87.83%\n",
    "Support Vector Machine: 94.73%\n",
    "Neural Network: 87.66%\n",
    "\n",
    "Additionally the accuracy of our heuristic was 88.7%\n",
    "\n",
    "## Task 4: Hypothesis Testing\n",
    "In order to compare the effectiveness of our heuristic to that of our machine learning algorithms, we decided to run a hypothesis test comparing the outcome of our heuristic to that of our most effective algorithm, support vector machine.\n",
    "\n",
    "H0: Our heuristic is as accurate as support vector machine\n",
    "H1: Our heuristic is not as accurate as support vector machine\n",
    "\n",
    "In order to test these hypotheses, we would run our naive bayes algorithm 30 times and get corresponding values for accuracy for each iteration. Applying the central limit theorem (because n ≥ 30), we then can approximate the distribution of the accuracy from the SVM algorithm by a normal distribution. We then want to test whether the mean of this distribution could potentially be equal to the accuracy derived from our heuristic. To do this we can perform a one sample t-test, seeing as we are only using one sample of accuracy values and our sample comes from a distribution which we can estimate as normal without knowing the population variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30/30\n",
      "Progress: [####################] 99.8%\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "# increase sample size by increasing n\n",
    "best_model = NuSVC()\n",
    "n = 30\n",
    "for i in range(n):\n",
    "    size = 1500 # size of each half of the dataset\n",
    "    data_set = get_dataset(size)\n",
    "\n",
    "    X_vectors = list(get_vectors_for_series(data_set[\"word\"], label=f\"Iteration {i+1}/{n}\"))\n",
    "\n",
    "    # Convert from list of np arrays to single 2darray\n",
    "    X = np.array([x for x in X_vectors])\n",
    "    y = np.array([np.array(1 if i else 0) for i in data_set[\"is_pronounceable\"]])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, list(y), test_size=0.25, random_state=7)\n",
    "    model = best_model.fit(X_train, y_train)\n",
    "    accuracies.append(svc_model.score(X_test, y_test))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The t-statistic is 66.922 and the p-value is 0.000.\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "assert len(accuracies) == 30\n",
    "# all values in accuracies list are probabilities\n",
    "assert max([0 if is_probability(sample) else 1 for sample in accuracies]) == 0\n",
    "assert is_probability(accuracy_dict[\"Heuristic Model\"])\n",
    "\n",
    "one_sample = stats.ttest_1samp(accuracies, accuracy_dict[\"Heuristic Model\"])\n",
    "print(\"The t-statistic is %.3f and the p-value is %.3f.\" % one_sample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the SVM algorithm 30 times and storing the accuracy data into a list, we can call the ttest_1samp function from the scipy package in order to perform this test, passing in the accuracy from our heuristic as the value for H0.\n",
    "\n",
    "\n",
    "## Task 5: Insights attained\n",
    "We reject the null hypothesis that our heuristic is as accurate as the support vector machine. However, our model still had a rather high mark for accuracy ass it predicted the probability that a word was pronounceable or not with an 88.7% accuracy. It is worth noting that while our algorithm did run slower than the support vector machine, itr was more memory efficient since we did not have to one-hot encode all of the bigrams. Even though we were unable to develop a model that had perfect predictions, it did help us all learn a little bit more about the English language and the way that syllables are used to form words, which was an invaluable bit of knowledge.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df02df53c6f155dcf3a9ac3da02c7726005cbaf8547c90b5015c1aa7bf9fe43a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
